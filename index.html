<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mohammad Rezaei - Personal Page</title>
    <link rel="stylesheet" href="style.css"> </head>
<body>
    <header>
        <div class="hero">
            <h1>Mohammad Rezaei</h1>
            <p class="tagline">Where Creativity Meets Technology</p>
            <p>I'm a computer scientist with a keen interest in statistical modeling and deep learning, particularly their applications in NLP and computer vision.</p>
            <a href="#projects" class="button">View My Projects</a>
            </div>
    </header>

    <main>
        <section id="about">
            <h2>About Me</h2>
            <p>I'm a computer scientist with a deep-seated passion for understanding and leveraging the power of data. My primary interests lie in the fascinating realms of statistical modeling and deep learning, where I'm particularly drawn to their transformative applications in Natural Language Processing and Computer Vision. I'm motivated by the potential of these technologies to solve complex real-world problems and build intelligent systems that can understand and interact with the world around us.</p>
            </section>

        <section id="projects">
            <h2>Projects</h2>
            <div class="project-grid">
                <div class="project-item">
                    <h3>TriHorn-Net</h3>
                    <img src="images/trihornnet.jpeg" alt="Screenshot of TriHorn-Net">
                    <p><strong>TriHorn-Net:</strong> I proposed and implemented a novel two-stage network architecture for hand pose estimation from depth images. This network, called TriHorn-Net, utilizes a unique combination of three attention-based branches to accurately predict joint positions. My approach, which includes a constrained UV branch and an unconstrained attention enhancement branch fused to guide feature pooling, achieves state-of-the-art performance in the field.</p>
                    <p><strong>Technologies Used:</strong> Python, Pytorch, Deep Learning</p>
                    <div class="project-links">
                        <a href="https://github.com/mrezaei92/TriHorn-Net" target="_blank">Github</a>
                        <span style="margin-left: 10px; margin-right: 10px;">|</span> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423004232" target="_blank">Paper</a>
                    </div>

                </div>

                <div class="project-item">
                    <h3>Weakly-supervised Hand Part Segmentation from Depth Images</h3>
                    <img src="images/handseg.png" alt="Screenshot of Handseg">
                    <p>This project addresses the challenge of requiring large amounts of labeled data for accurate part segmentation by proposing a novel data-driven method for hand part segmentation on depth maps. The key innovation is that it avoids the need for explicit segmentation labels by leveraging readily available 3D hand joint locations from existing datasets. The method learns to estimate hand shape and pose from depth maps, generates a 3D hand mesh, renders it using LBS weights, and derives segmentation labels from the rendered image. Evaluated on a manually annotated subset of the NYU dataset, the proposed approach achieves a mIoU of 42% without using any segmentation-based labels during training, demonstrating its effectiveness. </p>
                    <p><strong>Technologies Used:</strong> Python, Pytorch, Deep Learning</p>
                    <div class="project-links">
                        <a href="https://github.com/mrezaei92/HandPartSegment" target="_blank">GitHub</a>
                        <span style="margin-left: 10px; margin-right: 10px;">|</span> <a href="https://dl.acm.org/doi/10.1145/3453892.3453902" target="_blank">Paper</a>

                    </div>
                </div>

                </div>
        </section>

        <section id="contact">
            <h2>Contact</h2>
            <p>Feel free to reach out!</p>
            <p><strong>Email:</strong> mohammad.rezaei92@gmail.com</p>
            </section>
    </main>

    <footer>
        <p>&copy; 2025 Mohammad Rezaei</p>
        </footer>

    </body>
</html>
